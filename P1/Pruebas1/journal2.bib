@Article{Fatima2025,
author={Fatima, N. Sabiyath
and Deepika, G.
and Anthonisamy, Arun
and Chitra, R. Jothi
and Muralidharan, J.
and Alagarsamy, Manjunathan
and Ramyasree, Kummari},
title={Enhanced Facial Emotion Recognition Using Vision Transformer Models},
journal={Journal of Electrical Engineering {\&} Technology},
year={2025},
month={Jan},
day={29},
abstract={Automation of facial emotion recognition is an important branch of artificial intelligence and computer vision that has many potential applications in mental health diagnostics, human--computer interaction and security. The existing methods, however, usually have weaknesses in robustness, scalability and computational efficiency. This work proposes a self-attention-based Vision Transformer method that treats images as sequences of patches to capture global dependencies and spatial relations more effectively than other methods. The model is trained and evaluated using a large-scale dataset. On average, the model achieves an overall accuracy of 97{\%}, with good precision, recall and F1 scores in most emotion categories. The model performed better and was more robust to variations in illumination and facial pose compared to other existing methods. This work takes a step forward in facial emotion recognition technology, providing a large-scale and efficient solution for real-world applications. Facial Emotion Recognition, a New Vision Transformer Based on Self-Attention for Machine Learning.},
issn={2093-7423},
doi={10.1007/s42835-024-02118-w},
url={https://doi.org/10.1007/s42835-024-02118-w}
}


